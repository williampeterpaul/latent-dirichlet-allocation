# latent-dirichlet-allocation

Topic modelling using Latent Dirichlet Allocation with Gibbs Sampling. This project was was built as an extension to [twitter.influx](https://github.com/williampeterpaul/twitter.influx) in an attempt to infer useful information through semantic analysis. For more information check the repo!

> LDA or latent Dirichlet allocation is a “generative probabilistic model” of a collection of composites made up of parts. In terms of topic modeling, the composites are documents and the parts are words and/or phrases (n-grams). But you could apply LDA to DNA and nucleotides, pizzas and toppings, molecules and atoms, employees and skills, or keyboards and crumbs.


## Prerequisites

[R](https://cran.r-project.org/mirrors.html)


## Contribute

If you have any idea for an improvement or found a bug, do not hesitate to open an issue. 
And if you have time clone this repo and submit a pull request and help me make this project kickass!
